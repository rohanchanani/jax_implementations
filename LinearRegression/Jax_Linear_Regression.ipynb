{
<<<<<<< HEAD
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyv0AFqU-1UG"
      },
      "source": [
        "#Jax Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHNci88b-35C"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap, random, tree_multimap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8c6FGJxO2J7"
      },
      "outputs": [],
      "source": [
        "#Returns a prediction value given inputs and parameters\n",
        "def pred(x, params):\n",
        "  return jnp.dot(params[\"weights\"], x) + params[\"bias\"]\n",
        "\n",
        "#Vectorized version of prediction file for batches of inputs (multiple rows)\n",
        "multiple_preds = vmap(pred, (0, None))\n",
        "\n",
        "#Given parameters, batch of inputs, and batch of corresponding true outputs, returns mean squared error.\n",
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jax_Linear_Regression",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Jax Linear Regression"
      ],
      "metadata": {
        "id": "zyv0AFqU-1UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap, random, tree_multimap"
      ],
      "metadata": {
        "id": "XHNci88b-35C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eval functions\n",
        "def pred(x, params):\n",
        "  return jnp.dot(params[\"weights\"], x) + params[\"bias\"]\n",
        "\n",
        "multiple_preds = vmap(pred, (0, None))\n",
        "\n",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
        "def mse(params, x_multiple, y_multiple):\n",
        "  print(x_multiple.shape)\n",
        "  prediction = multiple_preds(x_multiple, params)\n",
        "  actual = y_multiple\n",
        "  return jnp.mean(jnp.multiply(prediction - actual, prediction - actual))\n",
        "\n",
<<<<<<< HEAD
        "#Given parameters, batch of inputs, and batch of corresponding true outputs, returns R^2 value.\n",
=======
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
        "def score(params, x_multiple, y_multiple):\n",
        "  prediction = multiple_preds(x_multiple, params)\n",
        "  actual = y_multiple\n",
        "  return 1 - (jnp.dot(prediction - actual, prediction - actual) / jnp.dot(actual - jnp.mean(actual), actual - jnp.mean(actual)))"
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUFM0-D8_VQj"
      },
      "outputs": [],
      "source": [
        "class LinearRegression:\n",
        "  \n",
        "  #Given inputs and correct output, trains a one layer Linear Regression model.\n",
        "  def train(self, x_data, y_data, num_steps=1000, step_size=0.01, display_info_step=100):\n",
        "    dimension = x_data.shape[1]\n",
        "    key = random.PRNGKey(1509)\n",
        "\n",
        "    #Initialize parameters\n",
        "    w_key, b_key = random.split(key)\n",
        "    current_params = {\"weights\": random.normal(w_key, (dimension,)), \"bias\": random.normal(b_key)}\n",
        "\n",
        "    #At each step, updates the parameters with using the gradient of mse function\n",
        "    def training_step(params, x_multiple, y_multiple, step_size):\n",
        "      loss_gradients = grad(mse)(params, x_multiple, y_multiple)\n",
        "      return tree_multimap(lambda param, gradient: param - gradient * step_size, params, loss_gradients)\n",
        "    \n",
        "    #Compile training_step function with jit\n",
        "    jit_training_step = jit(training_step)\n",
        "    \n",
        "    #Now the actual training\n",
=======
      ],
      "metadata": {
        "id": "c8c6FGJxO2J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "\n",
        "  def train(self, x_data, y_data, num_steps=1000, step_size=0.01, display_info_step=100):\n",
        "    dimension = x_data.shape[1]\n",
        "    key = random.PRNGKey(1509)\n",
        "    w_key, b_key = random.split(key)\n",
        "    current_params = {\"weights\": random.normal(w_key, (dimension,)), \"bias\": random.normal(b_key)}\n",
        "\n",
        "    def training_step(params, x_multiple, y_multiple, step_size):\n",
        "      print(x_multiple.shape)\n",
        "      loss_gradients = grad(mse)(params, x_multiple, y_multiple)\n",
        "      return tree_multimap(lambda param, gradient: param - gradient * step_size, params, loss_gradients)\n",
        "    \n",
        "    jit_training_step = jit(training_step)\n",
        "    \n",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
        "    for i in range(num_steps):\n",
        "      current_params = jit_training_step(current_params, x_data, y_data, step_size)\n",
        "      if display_info_step > 0:\n",
        "        if i % display_info_step == 0:\n",
        "          print(f\"Step {i} R-Squared: {score(current_params, x_data, y_data)}\")\n",
        "\n",
<<<<<<< HEAD
        "    #Sets the model's coefficients and intercept properties to the final parameters\n",
        "    self.coefficients = current_params[\"weights\"]\n",
        "    self.intercept = current_params[\"bias\"]\n",
        "\n",
        "  #Given an input, returns a prediction using the stored parameters.\n",
=======
        "    self.coefficients = current_params[\"weights\"]\n",
        "    self.intercept = current_params[\"bias\"]\n",
        "\n",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
        "  def predict(self, x, multiple=False):\n",
        "    params = {\"weights\": self.coefficients, \"bias\": self.intercept}\n",
        "    if multiple:\n",
        "      return multiple_preds(x, params)\n",
        "    else:\n",
<<<<<<< HEAD
        "      return pred(x, params)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL_OO8YDZWIT"
      },
      "outputs": [],
=======
        "      return pred(x, params)\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "hUFM0-D8_VQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd"
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "XBgqaEYPVzas",
        "outputId": "7b74ef4a-242e-4f9b-acf6-b4ede9d1114f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
=======
      ],
      "metadata": {
        "id": "dL_OO8YDZWIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house_data = pd.read_csv(\"train.csv\")"
      ],
      "metadata": {
        "id": "XBgqaEYPVzas",
        "outputId": "7b74ef4a-242e-4f9b-acf6-b4ede9d1114f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c6ae2837d00a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhouse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
<<<<<<< HEAD
      ],
      "source": [
        "house_data = pd.read_csv(\"house_train.csv\")"
=======
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": null,
      "metadata": {
        "id": "cxhBDs-bX8v2"
      },
      "outputs": [],
=======
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "source": [
        "def sorting(df, target):\n",
        "  preparation_df = df.copy()\n",
        "  preparation_df.fillna('none', inplace=True)\n",
        "  dtype_list = preparation_df.dtypes.tolist()\n",
        "  for idx, val in enumerate(dtype_list):\n",
        "    dtype_list[idx] = str(val)\n",
        "  categorical_variables = []\n",
        "  for idx, val in enumerate(preparation_df.columns.tolist()):\n",
        "    if dtype_list[idx] == 'object':\n",
        "      categorical_variables.append(val)\n",
        "  categorical_variables.append('MSSubClass')\n",
        "  sort_columns = []\n",
        "  for column in categorical_variables:\n",
        "    sort_columns.append(preparation_df.groupby(column).mean().sort_values(by=target).index.tolist())        \n",
        "  return sort_columns, categorical_variables"
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBT55tS4YeYH"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "cxhBDs-bX8v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "source": [
        "def preparation(df, sorted_columns_list, categorical_variables):\n",
        "    preparation_df = df.copy()\n",
        "    preparation_df.fillna('none', inplace=True)\n",
        "    for column in categorical_variables:\n",
        "        globals()['{}_list'.format(column)] = preparation_df[column].tolist()\n",
        "        for idx, val in enumerate(sorted_columns_list[categorical_variables.index(column)]):\n",
        "            for index, value in enumerate(globals()['{}_list'.format(column)]):\n",
        "                if value == val:\n",
        "                    globals()['{}_list'.format(column)][index]=idx\n",
        "        preparation_df[column]=globals()['{}_list'.format(column)]\n",
        "        preparation_df.replace('none', 0, inplace=True)\n",
        "    return preparation_df"
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaZ1I4BIYe5t"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "XBT55tS4YeYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "source": [
        "def correlation(df, target, corr_constant):\n",
        "    preparation_df = df.copy()\n",
        "    correlation_df = preparation_df.corr()\n",
        "    features = correlation_df[abs(correlation_df[target])>corr_constant][[target]].index.tolist()\n",
        "    return features[0:-1]"
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSmAjkGCYjQL"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "JaZ1I4BIYe5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "source": [
        "def variable_prep(prepped_df):\n",
        "    X = preprocessing.StandardScaler().fit(prepped_df).transform(prepped_df.astype(float))\n",
        "    return X"
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqGe_UGKYbIn"
      },
      "outputs": [],
=======
      ],
      "metadata": {
        "id": "hSmAjkGCYjQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "source": [
        "def train_test_prep(train_df, test_df, target, corr_constant):\n",
        "    sorted_columns, categorical_variables = sorting(train_df, target)\n",
        "    prepped_train_df = preparation(train_df, sorted_columns, categorical_variables)\n",
        "    features = correlation(prepped_train_df, target, corr_constant)\n",
        "    prepped_test_df = preparation(test_df, sorted_columns, categorical_variables)\n",
        "    y_train = np.array(prepped_train_df[target])\n",
        "    prepped_train_df.drop(\"SalePrice\", 1)\n",
        "    X_test = variable_prep(prepped_test_df[features])\n",
        "    X_train = variable_prep(prepped_train_df[features])\n",
        "    return X_train, y_train, X_test"
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaOLkaTJYb99"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, _ = train_test_prep(house_data, house_data.drop(\"SalePrice\", axis=1), \"SalePrice\", 0.06)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
=======
      ],
      "metadata": {
        "id": "CqGe_UGKYbIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data, y_data, _ = train_test_prep(house_data, house_data.drop(\"SalePrice\", axis=1), \"SalePrice\", 0.06)"
      ],
      "metadata": {
        "id": "gaOLkaTJYb99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "model.train(x_data, y_data)"
      ],
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9-Tl7FVZs7u",
        "outputId": "78ce20fa-24b5-48be-ec1c-e66387a76ea5"
      },
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
          "text": [
            "(1460, 67)\n",
            "(1460, 67)\n",
            "Step 0 R-Squared: -4.616201400756836\n",
            "Step 100 R-Squared: 0.7634928226470947\n",
            "Step 200 R-Squared: 0.8541419506072998\n",
            "Step 300 R-Squared: 0.8570235967636108\n",
            "Step 400 R-Squared: 0.8576697707176208\n",
            "Step 500 R-Squared: 0.858012318611145\n",
            "Step 600 R-Squared: 0.8582216501235962\n",
            "Step 700 R-Squared: 0.8583570718765259\n",
            "Step 800 R-Squared: 0.8584475517272949\n",
            "Step 900 R-Squared: 0.8585088849067688\n"
          ]
        }
<<<<<<< HEAD
      ],
      "source": [
        "model = LinearRegression()\n",
        "model.train(x_data, y_data)"
=======
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "print(model.coefficients)\n",
        "print(model.intercept)"
      ],
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM1Z2xPdPOM8",
        "outputId": "f0e12080-a0f7-489f-ff6f-a99c1ab176af"
      },
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
          "text": [
            "[-2304.588       42.10295   4200.547     1618.1536     635.2579\n",
            "  2041.2012    1635.4426   12022.644     2205.7495   -1884.1558\n",
            "  3727.7793    -456.05234  12091.685     6282.655     1024.4338\n",
            " -2006.2737    2310.322     4183.5156    1363.8425     175.31981\n",
            " -2696.882     8340.476     4746.1924    -141.59502   1073.7736\n",
            "  4201.6626   -3491.3027    4275.466    -1118.3302    4286.069\n",
            "   755.6142   -1419.5288    3192.6128    -133.51602   1013.94275\n",
            "   445.72784  -1477.3622    8510.692     7479.5444   11286.721\n",
            "  2873.273     1207.6199     976.81805  -3052.6152   -3019.74\n",
            "  5863.918     6386.53      3142.1365    2424.504      375.67484\n",
            " -1841.8363     263.46204     55.584454  5586.49      1283.6678\n",
            "   114.65431  -2226.829      -68.69399   2418.2124    -129.31169\n",
            "  -336.16888   2187.6536   -8785.606     9677.463     -216.31047\n",
            "  4385.724     2534.7065  ]\n",
            "180920.81\n"
          ]
        }
<<<<<<< HEAD
      ],
      "source": [
        "print(model.coefficients)\n",
        "print(model.intercept)"
=======
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "score({\"weights\": model.coefficients, \"bias\": model.intercept}, x_data, y_data)"
      ],
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJXZwplPRgMB",
        "outputId": "8eedebb0-de44-464b-b6ff-ba546a9f79a9"
      },
<<<<<<< HEAD
      "outputs": [
        {
=======
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
          "data": {
            "text/plain": [
              "DeviceArray(0.85855097, dtype=float32)"
            ]
          },
<<<<<<< HEAD
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score({\"weights\": model.coefficients, \"bias\": model.intercept}, x_data, y_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Jax_Linear_Regression",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
=======
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}
>>>>>>> 3f0ff231053bccdc029852161231df96bb2ccf74
